1、课程中会用到Apache和CDH两个版本
2、由于hive是依赖于Hadoop的，所以先把Hadoop相关的服务启动（HDFS、YARN）
3、配置
	-》解压
    bin/hdfs dfs -mkdir       /tmp
    bin/hdfs dfs -mkdir       /user/hive/warehouse
    bin/hdfs dfs -chmod g+w   /tmp
    bin/hdfs dfs -chmod g+w   /user/hive/warehouse
-》创建一个文件夹用于保存hive的所有数据，便于管理
	4、元数据默认情况下是存储在derby数据库中的
	5、hive在HDFS上的默认存储路径
	<property>
	  <name>hive.metastore.warehouse.dir</name>
	  <value>/user/hive/warehouse</value>
	  <description>location of default database for the warehouse</description>
	</property>
	6、修改hive-env.sh，注意改名
	# Set HADOOP_HOME to point to a specific hadoop install directory
	HADOOP_HOME=/opt/moduels/hadoop-2.5.0

	# Hive Configuration Directory can be controlled by:
	export HIVE_CONF_DIR=/opt/moduels/hive-0.13.1-bin/conf
	7、启动hive
		$ bin/hive